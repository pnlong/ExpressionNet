data:
  train_urls:
      - "/home/pnlong/musescore/amt/train.txt"
  validation_urls:
      - "/home/pnlong/musescore/amt/valid.txt"
  cache_dir: "/home/pnlong/musescore/amt/cache/"
  tokenizer: "passthrough"
  plaintext: True
  enforce_eos: False
  vocab_size: 55028
model:
  type: gpt2
  hidden_dim: 1024
  num_heads: 16
  num_layers: 24
  seq_len: 1024
  scale_attn_by_inverse_layer_idx: true
  embed_pdrop: 0.1
  resid_pdrop: 0.1
  gradient_checkpointing: true
trainer:
  mp: p=f32,c=bfloat16
  model_axis_size: 1
  per_device_parallelism: 16
  train_batch_size: 32
  num_train_steps: 100000
  checkpointer:
    base_path: /home/pnlong/musescore/amt/checkpoints/
    save_interval: 30m
  axis_resources:
    batch: "data"
    vocab: "model"
    mlp: "model"
    heads: "model"
  parameter_axis_resources:
    embed: "data"
  wandb:
    project: "PD^2"
optimizer:
  learning_rate: 3E-4
  weight_decay: 0.1
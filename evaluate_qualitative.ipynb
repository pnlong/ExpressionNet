{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Qualitative Evaluation of Model Performance\n",
    "\n",
    "Given the same prefix sequence of notes, does adding expressive features change model output? That is, do models respect expressive features?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Constants\n",
    "\n",
    "Some constants like filepaths and encodings for running this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# choose the data directory\n",
    "DATA_DIR = \"/home/pnlong/musescore/datavaa\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "from os.path import exists, basename\n",
    "from os import makedirs\n",
    "import numpy as np\n",
    "import representation\n",
    "import utils\n",
    "import torch\n",
    "import dataset\n",
    "import music_x_transformers\n",
    "import train\n",
    "from encode import extract_data\n",
    "import decode\n",
    "from read_mscz.read_mscz import read_musescore\n",
    "\n",
    "# filepaths\n",
    "TEST_DATA_DIR = \"/home/pnlong/musescore/test_data/evalqual\"\n",
    "if not exists(TEST_DATA_DIR):\n",
    "    makedirs(TEST_DATA_DIR)\n",
    "PREFIX_MSCZ_FILEPATH = f\"{TEST_DATA_DIR}/test.mscz\"\n",
    "if not exists(PREFIX_MSCZ_FILEPATH):\n",
    "    raise FileNotFoundError(\"Must provide a valid MuseScore prefix filepath.\")\n",
    "PREFIX_OUTPUT = basename(PREFIX_MSCZ_FILEPATH)\n",
    "\n",
    "# load the encoding\n",
    "encoding = representation.load_encoding(filepath = f\"{DATA_DIR}/encoding.json\")\n",
    "\n",
    "# some more variables\n",
    "include_velocity = (\"velocity\" in encoding[\"dimensions\"])\n",
    "use_absolute_time = not ((\"beat\" in encoding[\"dimensions\"]) and (\"position\" in encoding[\"dimensions\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare Prefix Sequence\n",
    "\n",
    "Prepare the prefix sequence by extracting relevant data from the MuseScore file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get BetterMusic object\n",
    "music = read_musescore(path = PREFIX_MSCZ_FILEPATH, timeout = 10)\n",
    "music.realize_expressive_features()\n",
    "\n",
    "# extract data from BetterMusic object\n",
    "music.tracks = [music.tracks[0],] # make sure it is just one track\n",
    "data = extract_data(music = music, use_implied_duration = True, include_velocity = include_velocity, use_absolute_time = use_absolute_time)\n",
    "\n",
    "# save encoded data\n",
    "prefix_path = f\"{TEST_DATA_DIR}/{basename(PREFIX_MSCZ_FILEPATH)}.npy\"\n",
    "np.save(file = prefix_path, arr = data)\n",
    "\n",
    "# text file with just the prefix path inside\n",
    "paths = f\"{TEST_DATA_DIR}/paths.txt\"\n",
    "with open(paths, \"w\") as paths_output:\n",
    "    paths_output.write(prefix_path + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## List the Models\n",
    "\n",
    "List the models that can be loaded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  - baseline_aug_ape_31M\n",
      "  - prefix_aug_ape_31M\n",
      "  - anticipation_aug_ape_31M\n",
      "  - prefix_conditional_aug_ape_31M\n",
      "  - anticipation_conditional_aug_ape_31M\n"
     ]
    }
   ],
   "source": [
    "with open(f\"{DATA_DIR}/models.txt\", \"r\") as models_output: # read in list of trained models\n",
    "    models = [model.strip() for model in models_output.readlines()]\n",
    "    for model in models:\n",
    "        print(f\"  - {model}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load a Model\n",
    "\n",
    "Specify the model to evaluate (from the list generated above) by setting the `model` field below. Then, load in the model's parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# which model to use\n",
    "model = \"baseline_aug_ape_31M\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get directories\n",
    "model_dir = f\"{DATA_DIR}/{model}\"\n",
    "evalqual_output_dir = f\"{model_dir}/evalqual\"\n",
    "if not exists(evalqual_output_dir):\n",
    "    makedirs(evalqual_output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating model...\n",
      "Loaded model weights from: /home/pnlong/musescore/datavaa/baseline_aug_ape_31M/checkpoints/best_model.valid.pth\n"
     ]
    }
   ],
   "source": [
    "# load training configurations\n",
    "train_args = utils.load_json(filepath = f\"{model_dir}/train_args.json\")\n",
    "\n",
    "# set the device to cpu\n",
    "device = torch.device(\"cpu\")\n",
    "\n",
    "# create the dataset\n",
    "max_seq_len = train_args[\"max_seq_len\"]\n",
    "test_dataset = dataset.MusicDataset(paths = paths, encoding = encoding, max_seq_len = max_seq_len, use_augmentation = False, is_baseline = False)\n",
    "\n",
    "# create the model\n",
    "print(\"Creating model...\")\n",
    "use_absolute_time = not ((\"beat\" in encoding[\"dimensions\"]) and (\"position\" in encoding[\"dimensions\"]))\n",
    "model = music_x_transformers.MusicXTransformer(\n",
    "    dim = train_args[\"dim\"],\n",
    "    encoding = encoding,\n",
    "    depth = train_args[\"layers\"],\n",
    "    heads = train_args[\"heads\"],\n",
    "    max_seq_len = max_seq_len,\n",
    "    max_temporal = encoding[\"max_\" + (\"time\" if use_absolute_time else \"beat\")],\n",
    "    rotary_pos_emb = train_args[\"rel_pos_emb\"],\n",
    "    use_abs_pos_emb = train_args[\"abs_pos_emb\"],\n",
    "    emb_dropout = train_args[\"dropout\"],\n",
    "    attn_dropout = train_args[\"dropout\"],\n",
    "    ff_dropout = train_args[\"dropout\"],\n",
    ").to(device)\n",
    "\n",
    "# load the checkpoint\n",
    "checkpoint_filepath = f\"{model_dir}/checkpoints/best_model.{train.PARTITIONS[1]}.pth\"\n",
    "model.load_state_dict(state_dict = torch.load(f = checkpoint_filepath, map_location = device))\n",
    "print(f\"Loaded model weights from: {checkpoint_filepath}\")\n",
    "model.eval()\n",
    "        \n",
    "# get special tokens\n",
    "sos = encoding[\"type_code_map\"][\"start-of-song\"]\n",
    "eos = encoding[\"type_code_map\"][\"end-of-song\"]\n",
    "note_token, grace_note_token = encoding[\"type_code_map\"][\"note\"], encoding[\"type_code_map\"][\"grace-note\"]\n",
    "expressive_token = encoding[\"type_code_map\"][representation.EXPRESSIVE_FEATURE_TYPE_STRING]\n",
    "\n",
    "# create data loader, get the singular batch\n",
    "test_data_loader = torch.utils.data.DataLoader(dataset = test_dataset, num_workers = 4, collate_fn = dataset.MusicDataset.collate, batch_size = 1, shuffle = False)\n",
    "test_iter = iter(test_data_loader)\n",
    "batch = next(test_iter)\n",
    "batch = batch[\"seq\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Sequences\n",
    "\n",
    "Now armed with the loaded model, generate a sequence given a prefix with and without expressive features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Notes Only\n",
    "\n",
    "Generate with a prefix of only notes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "`text` must not be None.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 21\u001b[0m\n\u001b[1;32m     19\u001b[0m music \u001b[38;5;241m=\u001b[39m decode\u001b[38;5;241m.\u001b[39mdecode(codes \u001b[38;5;241m=\u001b[39m generated_note[\u001b[38;5;241m0\u001b[39m], encoding \u001b[38;5;241m=\u001b[39m encoding) \u001b[38;5;66;03m# convert to a BetterMusic object\u001b[39;00m\n\u001b[1;32m     20\u001b[0m audio_output_note \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mevalqual_output_dir\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mPREFIX_OUTPUT\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.note.wav\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m---> 21\u001b[0m \u001b[43mmusic\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwrite\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43maudio_output_note\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/model_musescore/read_mscz/music.py:516\u001b[0m, in \u001b[0;36mBetterMusic.write\u001b[0;34m(self, path, kind, **kwargs)\u001b[0m\n\u001b[1;32m    514\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m write_musicxml(path \u001b[38;5;241m=\u001b[39m path, music \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    515\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m kind\u001b[38;5;241m.\u001b[39mlower() \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maudio\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;66;03m# write audio\u001b[39;00m\n\u001b[0;32m--> 516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mwrite_audio\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmusic\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    518\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpect `kind` to be \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmidi\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmusicxml\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, or \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maudio\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, but got : \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkind\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/model_musescore/read_mscz/output.py:508\u001b[0m, in \u001b[0;36mwrite_audio\u001b[0;34m(path, music, audio_format, soundfont_path, rate, gain, options)\u001b[0m\n\u001b[1;32m    504\u001b[0m \u001b[38;5;66;03m# create a temporary directory\u001b[39;00m\n\u001b[1;32m    505\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tempfile\u001b[38;5;241m.\u001b[39mTemporaryDirectory() \u001b[38;5;28;01mas\u001b[39;00m temp_dir:\n\u001b[1;32m    506\u001b[0m \n\u001b[1;32m    507\u001b[0m     \u001b[38;5;66;03m# ensure we are operating on a copy of music\u001b[39;00m\n\u001b[0;32m--> 508\u001b[0m     music \u001b[38;5;241m=\u001b[39m \u001b[43mdeepcopy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmusic\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    510\u001b[0m     \u001b[38;5;66;03m# write the BetterMusic object to a temporary .mid file\u001b[39;00m\n\u001b[1;32m    511\u001b[0m     midi_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtemp_dir\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/temp.mid\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/copy.py:153\u001b[0m, in \u001b[0;36mdeepcopy\u001b[0;34m(x, memo, _nil)\u001b[0m\n\u001b[1;32m    151\u001b[0m copier \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(x, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__deepcopy__\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m    152\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m copier \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 153\u001b[0m     y \u001b[38;5;241m=\u001b[39m \u001b[43mcopier\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmemo\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    154\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    155\u001b[0m     reductor \u001b[38;5;241m=\u001b[39m dispatch_table\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;28mcls\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/muspy/base.py:140\u001b[0m, in \u001b[0;36mBase.__deepcopy__\u001b[0;34m(self, memo)\u001b[0m\n\u001b[1;32m    139\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__deepcopy__\u001b[39m(\u001b[38;5;28mself\u001b[39m: BaseT, memo: \u001b[38;5;28mdict\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m BaseT:\n\u001b[0;32m--> 140\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_ordered_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/muspy/base.py:183\u001b[0m, in \u001b[0;36mBase.from_dict\u001b[0;34m(cls, dict_, strict, cast)\u001b[0m\n\u001b[1;32m    181\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m isclass(attr_type) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28missubclass\u001b[39m(attr_type, Base):\n\u001b[1;32m    182\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m attr \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_list_attributes:\n\u001b[0;32m--> 183\u001b[0m         kwargs[attr] \u001b[38;5;241m=\u001b[39m \u001b[43m[\u001b[49m\u001b[43mattr_type\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mv\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mv\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m    184\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    185\u001b[0m         kwargs[attr] \u001b[38;5;241m=\u001b[39m attr_type\u001b[38;5;241m.\u001b[39mfrom_dict(value)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/muspy/base.py:183\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    181\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m isclass(attr_type) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28missubclass\u001b[39m(attr_type, Base):\n\u001b[1;32m    182\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m attr \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_list_attributes:\n\u001b[0;32m--> 183\u001b[0m         kwargs[attr] \u001b[38;5;241m=\u001b[39m [\u001b[43mattr_type\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mv\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m v \u001b[38;5;129;01min\u001b[39;00m value]\n\u001b[1;32m    184\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    185\u001b[0m         kwargs[attr] \u001b[38;5;241m=\u001b[39m attr_type\u001b[38;5;241m.\u001b[39mfrom_dict(value)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/muspy/base.py:180\u001b[0m, in \u001b[0;36mBase.from_dict\u001b[0;34m(cls, dict_, strict, cast)\u001b[0m\n\u001b[1;32m    178\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m attr \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_optional_attributes:\n\u001b[1;32m    179\u001b[0m         \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[0;32m--> 180\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mattr\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m` must not be None.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    181\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m isclass(attr_type) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28missubclass\u001b[39m(attr_type, Base):\n\u001b[1;32m    182\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m attr \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_list_attributes:\n",
      "\u001b[0;31mTypeError\u001b[0m: `text` must not be None."
     ]
    }
   ],
   "source": [
    "# make sure prefix is correct\n",
    "prefix_note = batch[batch[:, :, 0] != encoding[\"type_code_map\"][representation.EXPRESSIVE_FEATURE_TYPE_STRING]].unsqueeze(dim = 0) # filter out expressive features\n",
    "\n",
    "# generate new samples\n",
    "generated_note = model.generate(\n",
    "    seq_in = prefix_note,\n",
    "    seq_len = train.DEFAULT_MAX_SEQ_LEN,\n",
    "    eos_token = eos,\n",
    "    temperature = 1.0,\n",
    "    filter_logits_fn = \"top_k\",\n",
    "    filter_thres = 0.9,\n",
    "    monotonicity_dim = (\"type\", \"time\" if use_absolute_time else \"beat\"),\n",
    "    notes_only = True\n",
    ")\n",
    "generated_note = torch.cat(tensors = (prefix_note, generated_note), dim = 1).numpy() # wrangle a bit\n",
    "np.save(file = f\"{evalqual_output_dir}/{PREFIX_OUTPUT}.note.npy\", arr = generated_note) # save as a numpy array\n",
    "\n",
    "# convert to audio\n",
    "music = decode.decode(codes = generated_note[0], encoding = encoding) # convert to a BetterMusic object\n",
    "audio_output_note = f\"{evalqual_output_dir}/{PREFIX_OUTPUT}.note.wav\"\n",
    "music.write(path = audio_output_note)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Notes and Expressive Features\n",
    "\n",
    "Generate with a prefix of notes and expressive features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make sure prefix is correct\n",
    "prefix_total = batch\n",
    "\n",
    "# generate new samples\n",
    "generated_total = model.generate(\n",
    "    seq_in = prefix_total,\n",
    "    seq_len = train.DEFAULT_MAX_SEQ_LEN,\n",
    "    eos_token = eos,\n",
    "    temperature = 1.0,\n",
    "    filter_logits_fn = \"top_k\",\n",
    "    filter_thres = 0.9,\n",
    "    monotonicity_dim = (\"type\", \"time\" if use_absolute_time else \"beat\"),\n",
    "    notes_only = True\n",
    ")\n",
    "generated_total = torch.cat(tensors = (prefix_total, generated_total), dim = 1).numpy() # wrangle a bit\n",
    "np.save(file = f\"{evalqual_output_dir}/{PREFIX_OUTPUT}.total.npy\", arr = generated_total) # save as a numpy array\n",
    "\n",
    "# convert to audio\n",
    "music = decode.decode(codes = generated_total[0], encoding = encoding) # convert to a BetterMusic object\n",
    "audio_output_total = f\"{evalqual_output_dir}/{PREFIX_OUTPUT}.total.wav\"\n",
    "music.write(path = audio_output_total)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's Compare the Audios!\n",
    "\n",
    "Compare the `.wav` files -- did adding expressive features make a difference?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import IPython\n",
    "print(\"NOTES ONLY\")\n",
    "IPython.display.display(IPython.display.Audio(audio_output_note))\n",
    "print(\"EXPRESSIVE FEATURES\")\n",
    "IPython.display.display(IPython.display.Audio(audio_output_total))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
